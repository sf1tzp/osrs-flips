{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "from osrs_filter import OSRSItemFilter\n",
    "\n",
    "from llm.client import ModelConfig, get_chat_response, init_client, remove_thinking_tags\n",
    "from utils.config import settings\n",
    "# Configuration\n",
    "BASE_URL = \"https://prices.runescape.wiki/api/v1/osrs\"\n",
    "\n",
    "# IMPORTANT: Set a descriptive User-Agent as required by the API\n",
    "# Replace with your own descriptive user agent\n",
    "USER_AGENT = \"learning pandas with osrs - @sf1tzp\"\n",
    "\n",
    "# Default headers with proper User-Agent\n",
    "HEADERS = {\n",
    "    'User-Agent': USER_AGENT,\n",
    "    'Accept': 'application/json'\n",
    "}\n",
    "\n",
    "print(f\"Using User-Agent: {USER_AGENT}\")\n",
    "print(f\"Base URL: {BASE_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e59e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize with forced reload to clear cached timezone-naive data\n",
    "print(\"Reinitializing OSRSItemFilter with fresh data...\")\n",
    "item_filter = OSRSItemFilter(user_agent=USER_AGENT)\n",
    "item_filter.load_data(force_reload=True)\n",
    "item_filter.apply_filter(\n",
    "    margin_pct_min=3,\n",
    "    sold_price_max=3200000,\n",
    "    sold_price_min=80000,\n",
    "    max_hours_since_update=0.25,\n",
    "    sort_by=(\"margin_gp\", \"desc\"),\n",
    "    limit=300\n",
    "\n",
    ")\n",
    "print(f\"Requsting volume data at: {datetime.now()}\")\n",
    "item_filter.load_volume_data(max_items=10000)\n",
    "print(f\"Volume data fetching complete at: {datetime.now()}\")\n",
    "\n",
    "# Example of saving filtered data to files in different formats\n",
    "print(\"Saving filtered data to files...\")\n",
    "\n",
    "# Save to Pickle (best for preserving all data types)\n",
    "item_filter.save(\"filtered_items.pkl\", format=\"pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4088eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_filter.save(\"filtered_items.pkl\", format=\"pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d996d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_filter = OSRSItemFilter(user_agent=USER_AGENT)\n",
    "loaded_filter.load_from_file(\"filtered_items.pkl\", format=\"pickle\")\n",
    "loaded_filter.apply_filter(\n",
    "    volume_24h_min=500,\n",
    "    volume_1h_min=100\n",
    ")\n",
    "\n",
    "with open(\"loaded_filter.txt\", \"w\") as file:\n",
    "    file.write(str(loaded_filter))\n",
    "\n",
    "# Save with improved formatting for LLM\n",
    "loaded_filter.save(\"loaded_filter.json\", format=\"json\")\n",
    "\n",
    "\n",
    "loaded_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# note: our bot will not save & load intermediate data to disk\n",
    "with open(\"loaded_filter.json\", \"r\") as f:\n",
    "    data_json = f.read()\n",
    "\n",
    "\n",
    "with open(\"over-here!.txt\", \"r\") as f:\n",
    "    data_text = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prototype LLM interaction using get_generate_response\n",
    "from llm.client import ModelConfig, get_generate_response\n",
    "# Configure qwen3:14b with 10k token context\n",
    "model_config = ModelConfig.create_default(\"qwen3:14b\")\n",
    "model_config.options.num_ctx = 20000  # 10k token context\n",
    "\n",
    "# Read the prompt.txt file as system prompt\n",
    "with open(\"../prompt.md\", \"r\") as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "with open(\"../signals.md\", \"r\") as f:\n",
    "    signals = f.read()\n",
    "\n",
    "with open(\"../example-output.md\", \"r\") as f:\n",
    "    example = f.read()\n",
    "\n",
    "full_prompt=f\"\"\"\n",
    "{prompt}\n",
    "\n",
    "<signals>\n",
    "{signals}\n",
    "</signals>\n",
    "\n",
    "<example grade=\"a great example\">\n",
    "{example}\n",
    "</example>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "user_prompt = f\"{data_json}\"\n",
    "\n",
    "# Get response from LLM\n",
    "response = get_generate_response(\n",
    "    model_config=model_config,\n",
    "    system_prompt=full_prompt,\n",
    "    user_prompt=user_prompt\n",
    ")\n",
    "\n",
    "# Clean the response by removing thinking tags\n",
    "cleaned_response = remove_thinking_tags(response.response)\n",
    "\n",
    "print(\"Cleaned response (without thinking tags):\")\n",
    "print(f\"Generated at: {datetime.now()}\\n\")\n",
    "print(\"=\" * 50)\n",
    "print(cleaned_response)\n",
    "\n",
    "# Save the cleaned response to a separate file\n",
    "with open(\"llm_trading_analysis_json.md\", \"w\") as f:\n",
    "    f.write(cleaned_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "user_prompt = f\"{data_text}\"\n",
    "\n",
    "# Get response from LLM\n",
    "response = get_generate_response(\n",
    "    model_config=model_config,\n",
    "    system_prompt=full_prompt,\n",
    "    user_prompt=user_prompt\n",
    ")\n",
    "\n",
    "# Clean the response by removing thinking tags\n",
    "cleaned_response = remove_thinking_tags(response.response)\n",
    "\n",
    "print(\"Cleaned response (without thinking tags):\")\n",
    "print(f\"Generated at: {datetime.now()}\\n\")\n",
    "print(\"=\" * 50)\n",
    "print(cleaned_response)\n",
    "\n",
    "# Save the cleaned response to a separate file\n",
    "with open(\"llm_trading_analysis_text.md\", \"w\") as f:\n",
    "    f.write(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8454f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osrs-flipping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
