{"id":"osrs-flips-1zg","title":"Implement shared rate limiter for collector components","description":"Extract rate limiting so Backfiller and GapFiller can share a single limiter when running concurrently.\n\n## Acceptance Criteria\n- Backfiller and GapFiller accept optional external rate.Limiter\n- If not provided, create internal limiter (backwards compatible)\n- Combined mode passes shared limiter to both\n- Total API calls stay within acceptable limits (e.g., 10 req/s combined)","status":"tombstone","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T12:31:02.501589263Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:49:42.987861524Z","deleted_at":"2026-02-03T12:49:42.987861524Z","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"osrs-flips-4cm","title":"Implement historical backfill from /timeseries","description":"Backfill historical data using the /timeseries endpoint.\n\n## Requirements\n- Fetch 24h → 1h → 5m buckets per item\n- Work backwards from present\n- Rate-limited to respect API\n- Populate price_buckets with source='api'\n\n## Considerations\n- Need to handle 4000+ items\n- Should be resumable if interrupted\n- Track backfill progress\n\n## Acceptance Criteria\n- Can backfill specified time range\n- Respects rate limits\n- Progress tracking/resumption","status":"closed","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T08:57:40.188909961Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T10:38:23.105168771Z","closed_at":"2026-02-03T10:38:23.105168771Z","close_reason":"Closed","dependencies":[{"issue_id":"osrs-flips-4cm","depends_on_id":"osrs-flips-al8","type":"parent-child","created_at":"2026-02-03T08:58:12.229133335Z","created_by":"Steven Fitzpatrick"},{"issue_id":"osrs-flips-4cm","depends_on_id":"osrs-flips-bl0","type":"blocks","created_at":"2026-02-03T08:58:35.737026375Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-4gc","title":"Add --combined flag and CLI integration for collector","description":"Add CLI flag to enable combined mode, decide on default behavior.\n\n## Acceptance Criteria\n- --combined flag runs all three modes concurrently\n- Existing flags (--backfill, --gap-fill) still work for single-mode operation\n- Consider making combined mode the default\n- Update help text and logging to reflect mode","status":"tombstone","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T12:31:08.821060995Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:49:42.987861524Z","deleted_at":"2026-02-03T12:49:42.987861524Z","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"osrs-flips-4xj","title":"Implement gap filling service","description":"Fill missing data gaps using /5m endpoint and computed buckets.\n\n## Requirements\n- Hourly: Check for missing 5m buckets in last 24h\n- Fill gaps via /5m API endpoint\n- Daily: Backfill missing larger buckets\n\n## Design Notes\n- Use /5m for surgical gap filling (point-in-time snapshot)\n- Prefer API buckets over computed (include volume data)\n\n## Acceptance Criteria\n- Automated gap detection\n- Gap filling via API","design":"## Runtime Considerations\n\n### API Endpoints\n- `/5m` endpoint: Returns ALL items in one call (efficient for current state)\n- `/timeseries`: Per-item calls required, 100ms rate limit = ~7.5 min for all items\n\n### Retention-Aware Filling\n- 5m gaps: Only fill gaps \u003c 7 days old (matches retention policy)\n- 1h gaps: Only fill gaps \u003c 1 year old\n- 24h gaps: No limit (kept forever)\n\n### Pacing Strategy\n**Option A: Aggressive (run daily)**\n- Fill all gaps in one session\n- ~22 min runtime for full scan\n- Risk: May strain API during peak hours\n\n**Option B: Conservative (recommended)**\n- Process N items per night (e.g., 100-200 items)\n- Prioritize high-value items (active trading, recent observations)\n- Full cycle completes over ~30 days\n- Respects API as community resource\n\n### Implementation Notes\n1. Query for gaps: Compare expected buckets vs actual in DB\n2. Skip items with no observations in last 7 days (inactive)\n3. Use config for pacing: `gap_fill_items_per_run: 150`\n4. Track progress in DB: `gap_fill_checkpoint` table\n5. Run during off-peak hours (2-4 AM UTC)\n\n### Gap Detection Query (5m example)\n```sql\nWITH expected AS (\n  SELECT generate_series(\n    NOW() - INTERVAL '7 days',\n    NOW(),\n    INTERVAL '5 minutes'\n  ) AS bucket_start\n),\nactual AS (\n  SELECT DISTINCT bucket_start \n  FROM price_buckets_5m \n  WHERE bucket_start \u003e NOW() - INTERVAL '7 days'\n)\nSELECT e.bucket_start\nFROM expected e\nLEFT JOIN actual a ON e.bucket_start = a.bucket_start\nWHERE a.bucket_start IS NULL;\n```","notes":"## Refined Acceptance Criteria\n\n1. **Retention-aware**: Never attempt to fill gaps older than retention policy\n2. **Pacing**: Configurable items-per-run limit (default: 150)\n3. **Priority**: Process items with recent activity first\n4. **Idempotent**: Safe to run multiple times; skips already-filled gaps\n5. **Observable**: Structured logging with snake_case events\n6. **Checkpoint**: Resumes from last position on restart\n\n## Logging Events\n\n| Event | Fields | Description |\n|-------|--------|-------------|\n| `gap_scan_started` | `bucket_size`, `retention_days` | Beginning gap detection |\n| `gap_scan_completed` | `bucket_size`, `items_scanned`, `gaps_found`, `duration_ms` | Scan finished |\n| `gap_fill_started` | `item_id`, `bucket_size`, `gap_count` | Filling gaps for item |\n| `gap_fill_completed` | `item_id`, `bucket_size`, `buckets_inserted` | Successfully filled |\n| `gap_fill_skipped` | `item_id`, `bucket_size`, `reason` | Skipped (e.g., `outside_retention`) |\n| `gap_fill_failed` | `item_id`, `bucket_size`, `error` | API or DB error |\n| `gap_fill_run_completed` | `items_processed`, `total_gaps_filled`, `errors`, `duration_ms` | Nightly run summary |","status":"closed","priority":3,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T08:57:45.990695519Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T11:50:15.373009325Z","closed_at":"2026-02-03T11:50:15.373009325Z","close_reason":"Implemented gap filling service with retention-aware pacing, structured logging, and CLI integration","dependencies":[{"issue_id":"osrs-flips-4xj","depends_on_id":"osrs-flips-al8","type":"parent-child","created_at":"2026-02-03T08:58:12.254113803Z","created_by":"Steven Fitzpatrick"},{"issue_id":"osrs-flips-4xj","depends_on_id":"osrs-flips-e5y","type":"blocks","created_at":"2026-02-03T08:58:35.764171619Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-5lz","title":"Add errgroup-based concurrent execution in collector","description":"Use errgroup.Group to run poller, backfiller, and gap-filler concurrently with proper error handling.\n\n## Acceptance Criteria\n- All three components run in separate goroutines\n- First error cancels all components\n- Clean shutdown on context cancellation\n- Proper logging for each component's lifecycle","status":"tombstone","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T12:31:04.15772319Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:49:42.987861524Z","deleted_at":"2026-02-03T12:49:42.987861524Z","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"osrs-flips-6yr","title":"Create item metadata table and population strategy","description":"Store item metadata (name, examine text, buy limits, etc.) for enriching price data and enabling selective volume polling.\n\n## Context\nPrice tables reference item_id (INTEGER), but we need item details for:\n- Display names in alerts/reports\n- Buy limits for flip calculations\n- Item categories/tags for filtering\n- **Selective volume polling** (only poll timeseries for flagged items)\n\n## API Source\nOSRS Wiki provides item mapping endpoint:\n- GET /mapping returns all item metadata\n- Fields: id, name, examine, members, lowalch, highalch, limit, value, icon\n\n## Schema\n```sql\nCREATE TABLE items (\n    item_id         INTEGER PRIMARY KEY,\n    name            TEXT NOT NULL,\n    examine         TEXT,\n    members         BOOLEAN DEFAULT FALSE,\n    buy_limit       INTEGER,\n    high_alch       INTEGER,\n    low_alch        INTEGER,\n    ge_value        INTEGER,\n    icon            TEXT,\n    -- Volume polling configuration\n    poll_volume     BOOLEAN DEFAULT FALSE,  -- Poll 5m timeseries for this item\n    updated_at      TIMESTAMPTZ DEFAULT NOW()\n);\n\nCREATE INDEX idx_items_poll_volume ON items(poll_volume) WHERE poll_volume = TRUE;\n```\n\n## Volume Polling Design\n- Items with `poll_volume=true` get their 5m timeseries polled\n- New VolumePoller service queries this table for target items\n- At 10 req/s rate limit, 100 items = 10 seconds per cycle\n- Volume data stored in existing price_buckets table\n\n## Open Questions\n- [x] How often does item data change? → Rarely (new items, limit changes)\n- [x] Populate on startup, or separate sync job? → Startup + daily refresh\n- [ ] Initial criteria for poll_volume flag? (high value? manual?)\n\n## Acceptance Criteria\n- Schema with poll_volume field created\n- Migration created and tested\n- Population from /mapping endpoint working\n- VolumePoller design documented (implementation separate)","status":"closed","priority":3,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T09:14:27.003308716Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:16:28.556810371Z","closed_at":"2026-02-03T12:16:28.556810371Z","close_reason":"Implemented items table schema, migration, repository methods, and ItemSyncer service. VolumePoller implementation tracked separately.","dependencies":[{"issue_id":"osrs-flips-6yr","depends_on_id":"osrs-flips-al8","type":"parent-child","created_at":"2026-02-03T09:17:11.229152851Z","created_by":"Steven Fitzpatrick"},{"issue_id":"osrs-flips-6yr","depends_on_id":"osrs-flips-bl0","type":"blocks","created_at":"2026-02-03T09:17:11.257095096Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-729","title":"Detect price inversions (high drops below low)","description":"Detect when high_price drops rapidly below low_price, indicating bot dumping or panic selling.\n\n## Signal Description\nWhen insta-buy price (high) drops below insta-sell price (low), it creates a negative margin - normally impossible in equilibrium. This signals:\n- Bots mass-selling items as fast as possible\n- Panic selling events\n- Potential buying opportunities\n\n## Volume Requirement\n**Critical**: A price inversion without volume spike is likely data noise. Real bot dumps show:\n- High price dropping below low price\n- Sharp increase in trade volume (high_price_vol)\n- Usually concentrated in 1-2 five-minute windows\n\nVolume data comes from the 5m timeseries API, which requires selective polling (see osrs-flips-6yr).\n\n## Implementation\n1. Query price_buckets for items with poll_volume=true\n2. Detect inversions: avg_high_price \u003c avg_low_price\n3. Require volume threshold: high_price_vol \u003e N * baseline_vol\n4. Surface in job output for LLM analysis\n\n## Files to Modify\n- pkg/storage/query_repository.go - Add inversion detection query\n- pkg/osrs/types.go - Add PriceInversion type\n- pkg/config/config.go - Add detection config\n- pkg/jobs/executor.go - Wire up detection\n\n## Blocked By\n- osrs-flips-6yr: Item metadata table with poll_volume field\n- VolumePoller service (design in 6yr, implementation TBD)","status":"open","priority":2,"issue_type":"feature","owner":"steven@fitz.gg","created_at":"2026-02-03T11:32:14.151344166Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:08:47.157979484Z","dependencies":[{"issue_id":"osrs-flips-729","depends_on_id":"osrs-flips-6yr","type":"blocks","created_at":"2026-02-03T12:08:21.593454823Z","created_by":"Steven Fitzpatrick"},{"issue_id":"osrs-flips-729","depends_on_id":"osrs-flips-ymy","type":"blocks","created_at":"2026-02-03T12:16:45.140435234Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-al8","title":"Persistent Price Data Storage","description":"Implement PostgreSQL + TimescaleDB storage for price data to reduce API abuse and enable historical analysis.\n\n## Goals\n- Store price observations from /latest polling (real-time)\n- Store pre-aggregated bucket data from API (historical)\n- Enable gap filling and data validation\n- Support hybrid queries across raw and bucketed data\n\n## Architecture Decision\n**Separate binary: `cmd/collector/main.go`**\n- Headless service dedicated to database maintenance\n- Runs independently from the Discord bot (`cmd/bot/`)\n- Responsibilities: polling, backfill, gap filling, lifecycle management\n- Query interface / Discord bot integration deferred to future effort\n\n## Configuration\n- Database connection via `DATABASE_URL` environment variable\n- External PostgreSQL + TimescaleDB instance (not managed by this project)\n\n## Reference\nSee plans/Persistance.md for detailed design notes.","status":"open","priority":1,"issue_type":"epic","owner":"steven@fitz.gg","created_at":"2026-02-03T08:57:20.555262025Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T09:28:45.359791309Z"}
{"id":"osrs-flips-bl0","title":"Create database schema for price data","description":"Implement the price data schema using TimescaleDB hypertables.\n\n## Design Decisions\n- Use TimescaleDB hypertables (learning exercise, simple automatic chunking)\n- Prices stored as INTEGER (matches in-game gold pieces, PostgreSQL aggregates return NUMERIC for precision)\n- Item IDs are INTEGER\n- Include ingested_at timestamps for debugging/auditing\n\n## Tables\n\n### 1. `price_observations` - Raw data from /latest polling\n```sql\nCREATE TABLE price_observations (\n    item_id        INTEGER NOT NULL,\n    observed_at    TIMESTAMPTZ NOT NULL,\n    high_price     INTEGER,\n    high_time      TIMESTAMPTZ,\n    low_price      INTEGER,\n    low_time       TIMESTAMPTZ,\n    ingested_at    TIMESTAMPTZ DEFAULT NOW(),\n    PRIMARY KEY (item_id, observed_at)\n);\n-- Convert to hypertable (chunks by observed_at)\nSELECT create_hypertable('price_observations', 'observed_at');\n```\n\n### 2. `price_buckets` - Pre-aggregated bucket data from API\n```sql\nCREATE TABLE price_buckets (\n    item_id           INTEGER NOT NULL,\n    bucket_start      TIMESTAMPTZ NOT NULL,\n    bucket_size       TEXT NOT NULL,  -- '5m', '1h', '24h'\n    avg_high_price    INTEGER,\n    high_price_volume BIGINT,\n    avg_low_price     INTEGER,\n    low_price_volume  BIGINT,\n    source            TEXT NOT NULL DEFAULT 'api',  -- 'api' or 'computed'\n    ingested_at       TIMESTAMPTZ DEFAULT NOW(),\n    PRIMARY KEY (item_id, bucket_start, bucket_size)\n);\nSELECT create_hypertable('price_buckets', 'bucket_start');\n```\n\n## Indexes (for target queries)\n\nTarget use cases:\n- Technical analysis (MACD, RSI): time-series for specific items\n- Price threshold alerts: lookup by item, compare current price\n\n```sql\n-- Hypertables auto-create time index, add item lookups\nCREATE INDEX idx_observations_item ON price_observations (item_id, observed_at DESC);\nCREATE INDEX idx_buckets_item ON price_buckets (item_id, bucket_start DESC);\n-- For threshold alerting (recent prices by item)\nCREATE INDEX idx_observations_item_prices ON price_observations (item_id, high_price, low_price);\n```\n\n## Tasks\n- [ ] Create migration: 001_enable_timescaledb.up.sql (CREATE EXTENSION)\n- [ ] Create migration: 002_price_observations.up.sql\n- [ ] Create migration: 003_price_buckets.up.sql\n- [ ] Create corresponding .down.sql migrations\n- [ ] Test migrations against local TimescaleDB instance\n- [ ] Document chunk interval tuning (default vs custom)\n\n## Acceptance Criteria\n- Hypertables created successfully\n- Indexes support item lookup + time range queries\n- Migrations reversible\n- Schema matches API response structure for easy ingestion\n\n## Notes\n- Item metadata table tracked separately (needs population strategy)\n- Chunk interval: start with TimescaleDB defaults, tune later based on data volume","status":"closed","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T08:57:30.28724963Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T10:12:54.550212955Z","closed_at":"2026-02-03T10:12:54.550212955Z","close_reason":"Closed","dependencies":[{"issue_id":"osrs-flips-bl0","depends_on_id":"osrs-flips-al8","type":"parent-child","created_at":"2026-02-03T08:58:12.175698056Z","created_by":"Steven Fitzpatrick"},{"issue_id":"osrs-flips-bl0","depends_on_id":"osrs-flips-vzg","type":"blocks","created_at":"2026-02-03T08:58:35.678932742Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-dri","title":"Add GetItemsNeedingSync repository method","description":"Create unified query that finds items needing historical data sync within retention windows.\n\n## Requirements\n- Finds new items with no bucket data for a given bucket_size\n- Finds existing items with gaps (actual_buckets \u003c expected_buckets)\n- Respects retention policy (5m=7d, 1h=1y, 24h=forever)\n- Prioritizes by recent observation activity\n- Accepts limit parameter for batch processing\n\n## Implementation\nMerge logic from:\n- GetBackfilledItems (items with no api-sourced data)\n- GetItemsWithGaps (items with incomplete coverage)\n\nInto single GetItemsNeedingSync(ctx, bucketSize, retention, limit) method.\n\n## Acceptance Criteria\n- Returns items that are new OR have gaps\n- Ordered by priority (recent activity first)\n- Tested with unit tests","status":"open","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T12:49:50.072289952Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:49:50.072289952Z"}
{"id":"osrs-flips-e5y","title":"Implement /latest polling ingestion","description":"Real-time continuous polling of the /latest endpoint.\n\n## Requirements\n- Poll /latest every 30-60 seconds\n- Insert all ~4000 items into price_observations\n- Handle connection failures gracefully\n- Configurable polling interval\n\n## Design Notes\n- Single API call captures all items\n- Enables sub-bucket resolution\n- Foundation for immediate alerting\n\n## Acceptance Criteria\n- Polling service runs continuously\n- Data written to price_observations table\n- Graceful error handling and retry logic","status":"closed","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T08:57:34.748869102Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T10:17:33.845061985Z","closed_at":"2026-02-03T10:17:33.845061985Z","close_reason":"Closed","dependencies":[{"issue_id":"osrs-flips-e5y","depends_on_id":"osrs-flips-al8","type":"parent-child","created_at":"2026-02-03T08:58:12.203366256Z","created_by":"Steven Fitzpatrick"},{"issue_id":"osrs-flips-e5y","depends_on_id":"osrs-flips-bl0","type":"blocks","created_at":"2026-02-03T08:58:35.709461426Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-ft5","title":"Update query layer to use persistent storage","description":"Refactor existing query/analysis code to use database instead of direct API calls.\n\n## Current Architecture\n\n**Data Flow:**\n```\nExecutor → Analyzer.LoadData() → Client.GetLatestPrices() → OSRS Wiki API\n         → Analyzer.LoadVolumeData() → Client.Get5mData() → OSRS Wiki API\n```\n\n**Key Files:**\n- `pkg/osrs/analyzer.go` - Main analysis logic, calls API via Client\n- `pkg/osrs/types.go` - ItemData, FilterOptions, PriceInfo structs\n- `pkg/jobs/executor.go` - Orchestrates job execution, uses Analyzer\n- `pkg/collector/repository.go` - Existing DB write operations\n\n**Field Mappings:**\n| API Field | DB Column | App Field |\n|-----------|-----------|-----------|\n| `high` | `high_price` | `InstaBuyPrice` |\n| `low` | `low_price` | `InstaSellPrice` |\n| `highTime` | `high_time` | `LastInstaBuyTime` |\n| `lowTime` | `low_time` | `LastInstaSellTime` |\n\n**Config filters use:**\n- `insta_sell_price_min/max` → filters on `low_price` (what sellers receive)\n- `insta_buy_price_min/max` → filters on `high_price` (what buyers pay)\n\n## Target Architecture\n\n**New Data Flow:**\n```\nExecutor → Analyzer.LoadData() → QueryRepository → PostgreSQL\n         → Fallback to API if data missing/stale\n```\n\n## Implementation Plan\n\n1. **Create QueryRepository** (`pkg/collector/query_repository.go`)\n   - `GetLatestPrices(ctx) → []ItemData` - Query most recent observation per item\n   - `GetVolumeMetrics(ctx, itemIDs, bucketSize) → map[int]VolumeMetrics` - Query from price_buckets_*\n   - `GetDataFreshness(ctx) → time.Time` - Check if local data is fresh enough\n\n2. **Update Analyzer** to accept data source interface\n   - Create `DataSource` interface with `LoadPrices()` and `LoadVolume()` methods\n   - Implement `DBDataSource` (uses QueryRepository)\n   - Implement `APIDataSource` (existing Client behavior)\n   - Analyzer uses DB first, falls back to API if stale/missing\n\n3. **Wire up in Executor**\n   - Inject QueryRepository into Analyzer\n   - Configure staleness threshold (e.g., 5 minutes)\n\n## Database Tables\n\n- `price_observations` - Raw polling data (7-day retention)\n- `price_buckets_5m` - 5-min aggregates (7-day retention)\n- `price_buckets_1h` - 1-hour aggregates (1-year retention)\n- `price_buckets_24h` - 24-hour aggregates (forever)\n\n## Acceptance Criteria\n- [ ] Existing job functionality preserved\n- [ ] Queries use local PostgreSQL data first\n- [ ] Falls back to API when local data is missing or stale (\u003e5 min)\n- [ ] Reduced API dependency during normal operation\n- [ ] Volume metrics come from price_buckets_* tables","status":"closed","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T08:57:54.537487413Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T11:21:42.161506472Z","closed_at":"2026-02-03T11:21:42.161506472Z","close_reason":"Implemented DataSource interface with API, DB, and Hybrid implementations. QueryRepository provides DB queries for prices and volume. JobRunner auto-detects DATABASE_URL and configures hybrid source with 5-minute freshness threshold.","dependencies":[{"issue_id":"osrs-flips-ft5","depends_on_id":"osrs-flips-al8","type":"parent-child","created_at":"2026-02-03T08:58:12.305038029Z","created_by":"Steven Fitzpatrick"},{"issue_id":"osrs-flips-ft5","depends_on_id":"osrs-flips-bl0","type":"blocks","created_at":"2026-02-03T08:58:35.815719373Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-i52","title":"Implement data lifecycle management","description":"Implement tiered data retention using separate tables per bucket resolution.\n\n## Design Decision\nSeparate tables per bucket size to enable TimescaleDB-native retention policies:\n\n| Table | Resolution | Retention | Policy |\n|-------|------------|-----------|--------|\n| `price_observations` | ~60s | 7 days | `add_retention_policy` |\n| `price_buckets_5m` | 5 min | 7 days | `add_retention_policy` |\n| `price_buckets_1h` | 1 hour | 1 year | `add_retention_policy` |\n| `price_buckets_24h` | 24 hour | Forever | No policy (optional compression) |\n\n## Rationale\n- 5m data is 12x larger than 1h for same time period (~28GB/year vs ~2.3GB)\n- 5m granularity only valuable for recent data (intraday analysis)\n- 1h resolution sufficient for historical trends and backtesting\n- Separate tables let TimescaleDB drop chunks efficiently (vs row DELETEs)\n\n## Tasks\n- [ ] Create migration: split `price_buckets` into three resolution-specific tables\n- [ ] Update `pkg/collector/repository.go` to write to correct table by bucket_size\n- [ ] Update `pkg/collector/backfiller.go` to use new table structure\n- [ ] Add retention policies via migration\n- [ ] Optional: Add compression policy for price_buckets_24h\n- [ ] Migrate existing data from price_buckets to new tables (if any)\n- [ ] Drop old price_buckets table\n\n## Acceptance Criteria\n- Each bucket resolution in its own hypertable\n- Retention policies active and working\n- Backfiller writes to correct tables\n- No application code needed for pruning (TimescaleDB handles it)","status":"closed","priority":3,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T08:57:49.144224394Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T10:56:39.362081736Z","closed_at":"2026-02-03T10:56:39.362081736Z","close_reason":"Closed","dependencies":[{"issue_id":"osrs-flips-i52","depends_on_id":"osrs-flips-al8","type":"parent-child","created_at":"2026-02-03T08:58:12.280741379Z","created_by":"Steven Fitzpatrick"},{"issue_id":"osrs-flips-i52","depends_on_id":"osrs-flips-bl0","type":"blocks","created_at":"2026-02-03T08:58:35.790290074Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-mbu","title":"Unify shutdown handling for combined collector mode","description":"Single signal handler that gracefully stops all collector components.\n\n## Acceptance Criteria\n- SIGINT/SIGTERM triggers shutdown of all components\n- Each component's Stop() method called\n- Wait for all goroutines to complete\n- Log shutdown progress for each component\n- Exit cleanly with appropriate status code","status":"tombstone","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T12:31:06.365846448Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:49:42.987861524Z","deleted_at":"2026-02-03T12:49:42.987861524Z","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"osrs-flips-o7a","title":"Remove deprecated Backfiller and GapFiller","description":"Clean up old code after BackgroundSync is working.\n\n## Tasks\n- Delete pkg/collector/backfiller.go\n- Delete pkg/collector/gap_filler.go\n- Remove GetBackfilledItems repository method (if unused)\n- Remove --backfill and --gap-fill CLI flags\n- Update any documentation\n\n## Acceptance Criteria\n- No dead code remaining\n- All tests pass\n- Combined mode is the only mode","status":"open","priority":3,"issue_type":"chore","owner":"steven@fitz.gg","created_at":"2026-02-03T12:50:03.264801951Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:50:03.264801951Z","dependencies":[{"issue_id":"osrs-flips-o7a","depends_on_id":"osrs-flips-of1","type":"blocks","created_at":"2026-02-03T12:50:08.326893537Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-of1","title":"Integrate combined collector mode","description":"Wire up Poller + BackgroundSync to run concurrently in single process.\n\n## Requirements\n- Both components run via Start() (non-blocking)\n- Shared rate limiter for API calls (optional - BackgroundSync is low-frequency)\n- Unified signal handler calls Stop() on both\n- Clean shutdown waits for both to finish\n\n## CLI Changes\n- Add --combined flag (or make it the new default)\n- Deprecate --backfill and --gap-fill flags\n- Keep them working temporarily with deprecation warning\n\n## Acceptance Criteria\n- Single binary runs both poller and background sync\n- Graceful shutdown works correctly\n- Logs clearly show both components' activity","status":"open","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T12:50:00.770439163Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:50:00.770439163Z","dependencies":[{"issue_id":"osrs-flips-of1","depends_on_id":"osrs-flips-pwj","type":"blocks","created_at":"2026-02-03T12:50:08.293973973Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-pwj","title":"Implement BackgroundSync component","description":"New component that continuously syncs historical price data, replacing both Backfiller and GapFiller.\n\n## API\n```go\ntype BackgroundSyncConfig struct {\n    BucketSizes   []string      // [\"5m\", \"1h\", \"24h\"]\n    RunInterval   time.Duration // How often to run sync cycle (e.g., 30m)\n    ItemsPerCycle int           // Max items per bucket per cycle\n    RateLimit     time.Duration // Between API calls (or accept external limiter)\n}\n\nfunc NewBackgroundSync(client, repo, config, logger) *BackgroundSync\nfunc (b *BackgroundSync) Start()  // Non-blocking, like Poller\nfunc (b *BackgroundSync) Stop()\n```\n\n## Behavior\n1. On each cycle: for each bucket_size, get items needing sync, fetch \u0026 upsert\n2. Sleep for RunInterval between cycles\n3. Graceful shutdown via Stop() or context cancellation\n4. Progress/stats logging\n\n## Acceptance Criteria\n- Handles both new items and gap repair\n- Non-blocking Start()/Stop() API (matches Poller)\n- Accepts optional shared rate.Limiter for combined mode\n- Integration tested","status":"open","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T12:49:56.602299219Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:49:56.602299219Z","dependencies":[{"issue_id":"osrs-flips-pwj","depends_on_id":"osrs-flips-dri","type":"blocks","created_at":"2026-02-03T12:50:08.257698675Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-tsv","title":"Combined collector mode with unified BackgroundSync","description":"Run poller and background sync within a single process instance.\n\n## Motivation\n- Simplifies deployment: single binary/container\n- Reduces operational overhead  \n- Better resource utilization (shared DB connections, single process)\n- Consolidates backfiller + gap-filler into one self-healing component\n\n## New Design\nTwo components running concurrently:\n1. **Poller**: Fetches /latest every 60s (live data)\n2. **BackgroundSync**: Continuously syncs historical data within retention windows\n\nBackgroundSync replaces both backfiller and gap-filler with unified logic:\n- Detects items needing data (new items OR items with gaps)\n- Fetches timeseries from API, upserts into price_buckets\n- Runs continuously with configurable interval\n- Self-healing: no external cron needed","design":"## Implementation Plan\n\n### Phase 1: Repository - GetItemsNeedingSync\nCreate unified query that finds items needing historical data sync:\n- New items with no bucket data (what backfiller caught)\n- Existing items with gaps within retention (what gap-filler caught)\n- Prioritized by recent activity\n\n### Phase 2: BackgroundSync Component\nNew component replacing both Backfiller and GapFiller:\n- Accepts shared rate.Limiter (for combined mode)\n- Configurable: bucket sizes, retention policy, run interval, items per cycle\n- Main loop: detect → fetch → upsert → sleep → repeat\n- Graceful shutdown via context + Stop()\n\n### Phase 3: Combined Mode Integration\n- Poller.Start() runs in background (existing)\n- BackgroundSync.Start() runs in background (new)\n- Shared rate limiter between BackgroundSync API calls\n- Unified shutdown handler\n\n### Phase 4: Cleanup\n- Deprecate/remove Backfiller\n- Deprecate/remove GapFiller\n- Update CLI flags (--combined becomes default or only mode)\n- Remove --backfill and --gap-fill flags\n\n## Retention Policy (unchanged)\n- 5m buckets: 7 days\n- 1h buckets: 1 year  \n- 24h buckets: forever","status":"open","priority":2,"issue_type":"feature","owner":"steven@fitz.gg","created_at":"2026-02-03T12:30:39.793457533Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:49:28.557547426Z","dependencies":[{"issue_id":"osrs-flips-tsv","depends_on_id":"osrs-flips-of1","type":"blocks","created_at":"2026-02-03T12:50:08.359296347Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-vzg","title":"Set up PostgreSQL + TimescaleDB infrastructure","description":"Configure database connectivity and migration tooling for price data storage.\n\n## Decisions\n- Database: External PostgreSQL + TimescaleDB instance (not managed in docker-compose)\n- Driver: pgx (native Go, built-in connection pooling)\n- Migrations: golang-migrate/migrate\n\n## Tasks\n- [ ] Add pgx dependency (`github.com/jackc/pgx/v5`)\n- [ ] Add golang-migrate dependency (`github.com/golang-migrate/migrate/v4`)\n- [ ] Create database configuration struct\n- [ ] Add environment variable support for DB connection:\n  - `DATABASE_URL` (connection string) or individual vars:\n  - `DB_HOST`, `DB_PORT`, `DB_USER`, `DB_PASSWORD`, `DB_NAME`\n  - `DB_POOL_MAX_CONNS` (optional, default sensible)\n  - `DB_SSL_MODE` (optional)\n- [ ] Create connection pool initialization with pgxpool\n- [ ] Set up migrations directory structure (`migrations/`)\n- [ ] Add migration runner to application startup\n- [ ] Update docker-compose.yml with new env vars\n- [ ] Document database setup in README\n\n## Acceptance Criteria\n- Application connects to external PostgreSQL via environment config\n- pgxpool connection pool configured with sensible defaults\n- Migration framework runs on startup (or via flag)\n- Graceful handling of connection failures","status":"closed","priority":2,"issue_type":"task","owner":"steven@fitz.gg","created_at":"2026-02-03T08:57:25.156537925Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T10:09:54.182431381Z","closed_at":"2026-02-03T10:09:54.182431381Z","close_reason":"Closed","dependencies":[{"issue_id":"osrs-flips-vzg","depends_on_id":"osrs-flips-al8","type":"parent-child","created_at":"2026-02-03T08:58:08.394276765Z","created_by":"Steven Fitzpatrick"}]}
{"id":"osrs-flips-ymy","title":"Implement VolumePoller service for selective 5m timeseries polling","description":"Poll 5m timeseries data for items with poll_volume=true to enable volume-based signal detection.\n\n## Context\nThe /latest endpoint provides prices but no volume data. Volume is critical for:\n- Detecting price inversions (osrs-flips-729) - need volume spike confirmation\n- Identifying bot dumps vs data noise\n- Understanding market activity\n\nThe 5m timeseries API has volume but is per-item, so we can only poll a subset.\n\n## Design\n1. Query items table for poll_volume=true items\n2. Poll /timeseries?id=X\u0026timestep=5m for each item\n3. Store results in price_buckets_5m table (already exists)\n4. Rate limit: 10 req/s max (100ms between requests)\n5. Poll interval: configurable, default 5 minutes\n\n## Implementation\n```go\ntype VolumePollerConfig struct {\n    PollInterval  time.Duration // How often to poll (default: 5m)\n    RateLimit     time.Duration // Delay between API calls (default: 100ms)\n    MaxConcurrent int           // Max concurrent requests (default: 1)\n}\n\ntype VolumePoller struct {\n    client *osrs.Client\n    repo   *Repository\n    config *VolumePollerConfig\n    logger *logging.Logger\n}\n```\n\n## Files to Create/Modify\n- pkg/collector/volume_poller.go (new)\n- pkg/collector/volume_poller_test.go (new)\n- cmd/collector/main.go (add --enable-volume-polling flag)\n\n## Acceptance Criteria\n- VolumePoller service polls items with poll_volume=true\n- Results stored in price_buckets_5m\n- Integrated into collector with feature flag\n- Graceful shutdown support\n- Rate limiting respected","status":"in_progress","priority":2,"issue_type":"feature","owner":"steven@fitz.gg","created_at":"2026-02-03T12:16:28.631429083Z","created_by":"Steven Fitzpatrick","updated_at":"2026-02-03T12:21:09.414224731Z"}
